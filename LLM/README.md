# GPT-like Large Language Model

## Concepts 

### Transformer

感觉不用分享，网上很多。

### Decoding process 

大模型解码过程一般有：

- 贪心解码（Greedy Decoding）：直接选择概率最高的单词。这种方法简单高效，但是可能会导致生成的文本过于单调和重复。
- 随机采样（Random Sampling）：按照概率分布随机选择一个单词。这种方法可以增加生成的多样性，但是可能会导致生成的文本不连贯和无意义。
- 集束搜索（Beam Search）：在每一个时间步，不再只保留当前概率最高的一个单词，而是按照概率从高到低排序，保留前num_beams个单词。这种方法可以平衡生成的质量和多样性，但也难以避免单词重复的问题。


#### Temperature 

温度(temperature): 温度用于控制人工智能生成文本的创造力水平的参数。通过调整“温度”，您可以影响AI模型的概率分布，使文本更加集中或更多样化。高的温度代表生成更加随机的词，低生成的词更加确定。范围在（0～2）之间，多数在（0～1）之间。

大模型（decoder-transformer)是基于自回归机制，每轮生成的是输出模型字典所有词的输出概率。

考虑以下示例：当没有温度这个参数的时候， 大模型必须完成句子“我想____”。下一个字具有以下标记概率：
```
吃: 0.2
玩: 0.5
睡: 0.1 
...其他词（当然，还有起始词，结束词等等）
```

当添加温度这个参数时候，我们本质上是控制/调节模型输出词的概率。

高温度的时候，比如1.5，下一个字具有以下标记概率：
```
吃: 0.13
玩: 0.2
睡: 0.1
...其他词（当然，还有起始词，结束词等等）
```
高温度相当于把所有的把输出分布的概率拉的更加平均，这个输出更加多样化，但是语言之间的相关性也被破坏掉，整体来说就会变得随机，也会出现语法/语义的混乱；

低温度的时候，比如0.2，下一个字具有以下标记概率：
```
吃: 0.18
玩: 0.8
睡: 0.07
...其他词（当然，还有起始词，结束词等等）
```
温度较低的时候，则对除对数概率最高的类之外的其他类进行采样的概率会很小，相当于输出概率变得更加尖锐（注意高温时输出概率分布是比较平整的）。整体生成变化变小，相当于固定输出。这个输出就是模型基于数据学习到最最相关的词，是模型认为最正确的文本。缺点就是比较固定，没有变化了。

#### Top_p

top_p的p是percentile，又称核心采样（Nucleus Sampling），用于控制 AI 模型根据累积概率考虑的标记范围。在统计学中，例如，如果你知道你的分数位于第90百分位，那意味着你的分数超过了90%的参考人，你的表现相对于其他人来说非常出色。所以，同理当我们的top_p 90%的时候，将候选单词按照概率从高到低排序，我们选取前90%模型输出logits作为参考范围。

考虑以下示例：当没有温度这个参数的时候， 大模型必须完成句子“我想____”。下一个字具有以下标记概率：
```
吃: 0.2
玩: 0.5
睡: 0.1 
...其他词（当然，还有起始词，结束词等等）
```

- 当top_p = 0.5时候，我们只能参考“玩”这个词，输出非常固定；
- 当top_p = 0.7时候，我们的选项有“玩”和“吃”，多了一些选择；
- 当top_p = 0.9时候，模型有更多的标记，“玩”，“吃”，“睡”等等，变化就多了

#### Top_k

top_k是最好理解的参数，简单说就是前k个选择。


考虑以下示例：当没有温度这个参数的时候， 大模型必须完成句子“我想____”。下一个字具有以下标记概率：
```
吃: 0.2
玩: 0.5
睡: 0.1 
...其他词（当然，还有起始词，结束词等等）
```


- 当top_k = 1时候，我们只能参考“玩”这个词；
- 当top_k = 3时候，我们的选项有“玩”,“吃”,"睡“


Top-k采样是一种生成文本的方法，具有以下优点：

- 控制多样性和质量：通过调整k的大小，可以平衡生成文本的多样性和质量。较大的k值会增加多样性但降低质量，较小的k值则相反。因此，根据任务和场景需求选择合适的k值。
- 结合其他解码策略：可与温度调节、重复惩罚、长度惩罚等策略结合使用，进一步优化生成效果。
然而，Top-k采样也存在一些缺点：

不符合常识或逻辑：
- 由于仅考虑单词的概率，可能导致生成文本与语义、语法关系不符。
- 过于简单或无聊：仅考虑概率最高的k个单词，可能忽略其他有意义或有创意的选择，导致生成文本缺乏趣味性。

#### Temperature、top_p & top_k

三者的联合使用一般是，先用top_k,选取k个最高概率的词，然后用top_p，保留钱p-pencentil个词，然后用temperature归一化，从上面的归一化概率中选取下一个词。

在特定的环境中，调节“Temperature”和“top_p”参数可以微调字生成的创新性和聚焦度。以下是各种可能性：
- 高温度低top_p：模型将重视高概率且范围狭窄的字，但高温度可能会为输出添加一些不确定性。
- 低温度高top_p：模型将给予广泛的字更多考虑，但会更多地选择最有可能的字，这可能会减少创新性的输出。
- 高温度高top_p：模型将考虑所有可能的字，并增加选取的随机性。这样的组合可能会产生有创新性但可能不太一致的输出。
- 低温度低top_p：模型将主要关注概率高且范围狭窄的字，低温度会使选取更为确定。这种组合可能会产生高度聚焦且可预见的输出。

#### Beam Search

[集束搜索](https://zhuanlan.zhihu.com/p/114669778)是一种针对贪心策略的优化方法。它的主要思路是适当地扩大考察的范围。每个时间步骤，不再仅选择当前概率最高的一个单词，而是保留num_beams个单词。当num_beams等于1时，集束搜索就会变成贪心搜索。每一轮都都会根据topk,toppd等生成最优的几个词，然后按照概率排序，选择number beams词，每个beam都会继续生成下一个预测，然后再从所有最优选择中挑出number beams，不断循环直至停止。



## 参考

- https://github.com/mru4913/build_MiniLLM_from_scratch