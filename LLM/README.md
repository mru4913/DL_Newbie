# GPT-like Large Language Model




## Concpets 

### Temperature 

温度(temperature): 温度用于控制人工智能生成文本的创造力水平的参数。通过调整“温度”，您可以影响AI模型的概率分布，使文本更加集中或更多样化。高的温度代表生成更加随机的词，低生成的词更加确定。范围在（0～2）之间，多数在（0～1）之间。

大模型（decoder-transformer)是基于自回归机制，每轮生成的是输出模型字典所有词的输出概率。

考虑以下示例：当没有温度这个参数的时候， 大模型必须完成句子“我想吃____”。下一个字具有以下标记概率：
```
吃: 0.2
玩: 0.5
睡: 0.1 
...其他词（当然，还有起始词，结束词等等）
```

当添加温度这个参数时候，我们本质上是控制/调节模型输出词的概率。

高温度的时候，比如1.5，下一个字具有以下标记概率：
```
吃: 0.13
玩: 0.2
睡: 0.1
...其他词（当然，还有起始词，结束词等等）
```
高温度相当于把所有的把输出分布的概率拉的更加平均，这个输出更加多样化，但是语言之间的相关性也被破坏掉，整体来说就会变得随机，也会出现语法/语义的混乱；

低温度的时候，比如0.2，下一个字具有以下标记概率：
```
吃: 0.18
玩: 0.8
睡: 0.07
...其他词（当然，还有起始词，结束词等等）
```
温度较低的时候，则对除对数概率最高的类之外的其他类进行采样的概率会很小，相当于输出概率变得更加尖锐（注意高温时输出概率分布是比较平整的）。整体生成变化变小，相当于固定输出。这个输出就是模型基于数据学习到最最相关的词，是模型认为最正确的文本。缺点就是比较固定，没有变化了。

## Top_p




